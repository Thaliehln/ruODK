---
title: "Accessing the OData API"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{odata}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
library(DT)
library(leaflet)
library(listviewer)
library(magrittr)
library(tibble)
# library(tidyr)
library(lubridate)
library(knitr)
library(dplyr)
library(ggplot2)
library(ruODK)
```

This vignette demonstrates `ruODK`'s workflow to extract data from ODK Central's
OData service endpoint, and to prepare the data and the media attachments for
further analysis and visualisation.

The demonstrated workflow is roughly equivalent to ODK Central's "Export all data",
which downloads all submissions and all repeating subgroups as CSV spreadsheets,
and all media attachments in a local subfolder "attachments".

An alternative pathway to getting data out of ODK Central is to use the REST API
as documented (with live examples in multiple programming languages) at the
[ODK Central API docs](https://odkcentral.docs.apiary.io/).

# Configure ruODK
The OData service URL is shown in the form's "Submissions" tab >
"Analyze via OData" on ODK Central. It contains base URL, project ID, and 
form ID and is used by `ruODK::ru_setup()`.

```{r ru_setup}
# ODK Central's OData URL contains base URL, project ID, and form ID
# ODK Central credentials can live in .Renviron, see vignette "setup"
ruODK::ru_setup(
  svc = "https://sandbox.central.opendatakit.org/v1/projects/14/forms/build_Flora-Quadrat-0-2_1558575936.svc",
  un = Sys.getenv("ODKC_TEST_UN"),
  pw = Sys.getenv("ODKC_TEST_PW")
)

# Canned data
data("fq_svc")
data("fq_meta")
data("fq_raw")
data("fq_tae")
```

To extract data from the OData API endpoints, we have to:

* discover data endpoints from the OData service document,
* inspect the metadata schema to infer data types,
* download submissions from the data endpoints,
* download media attachments and adjust their file paths to the downloaded files.

## OData service document
Let's start off with the service document.

```{r load_odata_service, eval=F}
fq_svc <- odata_service_get()
```

We'll use the included example data `fq_svc`.
```{r view_service}
fq_svc %>% knitr::kable(.)
```

`ruODK` provides the names and urls of the service endpoints as `tibble`.
We see the main data available under the url `Submissions`, and a repeating 
group called `taxon_encounter` in the ODK form under the url 
`Submissions.taxon_encounter`.

The number and names of repeating subgroups of course depends on the ODK form.

## OData metadata document
Next, let's get the metadata to review our data schema.
While we can download the submission data without it, the metadata document 
contains information about field data types and attachment names.
Future versions of `ruODK` might automate these steps.

```{r load_ometadata}
fq_meta <- odata_metadata_get()
```

```{r view_metadata, fig.width=7}
listviewer::jsonedit(fq_meta)
```

## OData submission data documents
Now let's download the form submissions and, separately, repeating form groups.

```{r load_odata}
fq_raw <- odata_submission_get()
fq_tae <- odata_submission_get(table = "Submissions.taxon_encounter")
```

The output of the above code is provided as data objects `fq_raw` 
(main submissions of form Flora Quadrat 0.2) and `fq_tae` (repeated group "Taxon 
Encounter" within a Flora Quadrat).

# Rectangle the data
The function `ruODK::odata_submission_get` returned the original XML response as a 
nested list of lists.
To analyse and visualise the data, this nested list of lists must be transformed 
into a rectangular shape.
The function `ruODK::odata_submission_parse` recursively unnests list columns using
`tidyr::unnest_wider`. Unnamed columns, notably the anonymous lat/lon/alt 
coordinates, are named automatically to become unique (a feature of 
`tidyr::unnest_*()`), and then sanitised using the helper `janitor::clean_names()`.

In this example, we clean up the output further by renaming some columns, notably
the main coordinates from `x13` and `x14` to `longitude` and `latitude`.

The vectorised function `ruODK::attachment_get` downloads and links attachments 
like photos and other media to a local, relative path. This will take some time
during the first run; once the files exist locally, the download will be skipped.
Read `??ruODK::attachment_get` on specifying form field names (or parts thereof)
indicating a media attachment; the default are any names containing "photo".

The date formats are parsed from ISO8601 timestamps into POSIXct objects with
`ruODK::parse_datetime`. We use our local timezone (GMT+08) in this example.
Read `??ruODK::parse_datetime` on specifying form field names (or parts thereof)
indicating a date field; the default are any names containing "time".

The trailing `invisible` is a neutral operation to allow trailing magrittr 
pipes (`%>%`) while commenting individual lines of the pipelines in or out.

The repeated subgroup `taxon_encounter` is joined with the main observation
to receive a (repeated) copy of the main observation's values 
(such as observation time and habitat description).

For clarity, we enable verbose messages from `odata_submission_parse` 
and preserve the message output in the code chunk options with `message=TRUE`.

```{r transform_data, message=TRUE}
ord <- "YmdHMSz"
tz <- "Australia/Perth"
  
fq_data <- fq_raw %>%
  ruODK::odata_submission_parse(verbose = TRUE) %>% 
  ruODK::parse_datetime(tz = "Australia/Perth") %>% 
  ruODK::parse_datetime(tz = "Australia/Perth", col_contains = "date") %>%
  dplyr::rename(
    longitude = x13,
    latitude = x14,
    altitude = x15
  ) %>%
  dplyr::mutate(
    quadrat_photo = attachment_get(id, quadrat_photo),
    morphological_type_photo = attachment_get(id, morphological_type_photo),
    mudmap_photo = attachment_get(id, mudmap_photo),

  ) %>%
  invisible()

fq_data_tae <- fq_tae %>%
  odata_submission_parse(verbose = TRUE) %>% 
  dplyr::rename(
    lon = x6,
    lat = x7,
    alt = x8
  ) %>%
  dplyr::mutate(
    photo_in_situ = attachment_get(submissions_id, photo_in_situ)
  ) %>%
  dplyr::left_join(fq_data, by = c("submissions_id" = "id")) %>%
  invisible()
```

Note: A manually resized version of the original photos in this example live in
the package source under 
[`docs/articles/attachments`](https://github.com/dbca-wa/ruODK/tree/master/docs/articles/attachments). 
To minimise package size, they were resized with imagemagick:
`find docs/articles/attachments/ -maxdepth 2 -type f -exec mogrify -resize 300x200 {} \;`.

## DIY rectangling
The unnesting could also be done manually by building up a pipeline, which
stepwise unnests each list column.
This requires knowledge of the data structure, which can either be looked up
from the metadata, or by inspecting the raw data, `fq_raw`.
```{r rectangle_diy}
fq_data_diy <- tibble::tibble(value = fq_raw$value) %>%
  tidyr::unnest_wider(value) %>%
  # 1. find list columns:
  tidyr::unnest_wider(`__system`) %>%
  tidyr::unnest_wider(meta) %>%
  # add more lines here to unnest other form groups
  #
  # 2. rename column names
  dplyr::rename(
    uuid = `__id`
    # add more columns, e.g.
    # longitude=`...1`, latitude=`...2`, altitude=`...3`
  ) %>%
  # 3. handle media attachments
  # dplyr::mutate(photo_field1 = attachment_get(data_url, uuid, photo_field1)) %>%
  invisible()
```

## Spatial formats - how granular would you like your coordinates?
If we run `odata_submission_get()` with `wkt=FALSE` (the default), we will
receive GeoJSON. Point GeoJSON parses with `parse_submissions` into separate 
columns for lat, lon, alt (soon accuracy). 
This is useful for e.g. leaflet maps which want lat and lon separately, see 
example map below.

If we run `odata_submission_get()` with `wkt=TRUE` (the default), we will
not surprisingly receive WKT. This is useful for spatial objects with 
non-deterministic length like lines and polygons. 
If encountering WKT, `parse_submissions` simply retains the WKT string 
containing the respective entire geometry. 
This can further be turned into spatially enabled objects. 

In future, we will add some examples for this use case here.

# Visualise data
This section provides some examples of standard data visualisations.

## Datatable
Package `DT` provides an interactive (and searchable) datatable.

```{r vis_data}
DT::datatable(fq_data)
DT::datatable(fq_data_tae)
DT::datatable(head(fq_data_diy))
```

## Map
Package `leaflet` provides interactive maps.

Constructing label and popup requires knowledge of the dataset structure.

```{r map_data}
leaflet::leaflet(width = 800, height = 600) %>%
  leaflet::addProviderTiles("OpenStreetMap.Mapnik", group = "Place names") %>%
  leaflet::addProviderTiles("Esri.WorldImagery", group = "Aerial") %>%
  leaflet::clearBounds() %>%
  leaflet::addAwesomeMarkers(
    data = fq_data,
    lng = ~longitude, lat = ~latitude,
    icon = leaflet::makeAwesomeIcon(text = "Q", markerColor = "red"),
    label = ~ glue::glue("{area_name} {encounter_start_datetime}"),
    popup = ~ glue::glue(
      "<h3>{area_name}</h3>",
      "Survey start {encounter_start_datetime}</br>",
      "Reporter {reporter}</br>",
      "Device {device_id}</br>",
      "<h5>Site</h5>",
      '<div><img src="{quadrat_photo}"',
      ' height="150px" alt="Quadrat photo"></img></div>',
      "<h5>Mudmap</h5>",
      '<div><img src="{mudmap_photo}',
      ' height="150px" alt="Mudmap"></img></div>',
      "<h5>Habitat</h5>",
      "Morphological type: {morphological_type}</br>",
      '<div><img src="{morphological_type_photo}"',
      'height="150px" alt="Morphological type"></img></div>',
      "Veg class: {vegclass_placeholder}</br>"
    ),
    clusterOptions = leaflet::markerClusterOptions()
  ) %>%
  leaflet::addLayersControl(
    baseGroups = c("Place names", "Aerial"),
    options = leaflet::layersControlOptions(collapsed = FALSE)
  )
```

```{r map_data_tae}
leaflet::leaflet(width = 800, height = 600) %>%
  leaflet::addProviderTiles("OpenStreetMap.Mapnik", group = "Place names") %>%
  leaflet::addProviderTiles("Esri.WorldImagery", group = "Aerial") %>%
  leaflet::clearBounds() %>%
  leaflet::addAwesomeMarkers(
    data = fq_data_tae,
    lng = ~lon, lat = ~lat,
    icon = leaflet::makeAwesomeIcon(text = "T", markerColor = "green"),
    label = ~ glue::glue("{canonical_name} {encounter_start_datetime}"),
    popup = ~ glue::glue(
      "<h3>{area_name}</h3>",
      "Survey start {encounter_start_datetime}</br>",
      "Reporter {reporter}</br>",
      "Device {device_id}</br>",
      "<h5>Taxon</h5>",
      '<div><img src="{photo_in_situ}"',
      ' height="150px" alt="Taxon in situ"></img></div>',
      "Specimen barcode: {voucher_specimen_barcode}</br>",
      "Life form: {life_form}</br>"
    ),
    clusterOptions = leaflet::markerClusterOptions()
  ) %>%
  leaflet::addLayersControl(
    baseGroups = c("Place names", "Aerial"),
    options = leaflet::layersControlOptions(collapsed = FALSE)
  )
```

## Summarising data
The data tibbles are now "tidy" for exploratory data analysis.
See Hadley Wickam's 
[R for Data Science](https://r4ds.had.co.nz/exploratory-data-analysis.html)
for more background.

```{r eda, fig.height=5, fig.width=7}
# How many submissions per device?
fq_data %>% 
  dplyr::group_by(instance_id) %>% 
  dplyr::tally() %>% 
  knitr::kable()

# How many species sightings per life form?
fq_data_tae %>% 
  dplyr::group_by(life_form) %>% 
  dplyr::tally() %>% 
  knitr::kable()

# GGplot of a pivot table
fq_data_tae %>%
  dplyr::group_by(life_form) %>%
  dplyr::tally() %>%
  ggplot2::ggplot(ggplot2::aes(x = life_form, y = n)) +
  ggplot2::labs(
    title = "Title",
    subtitle = "Subtitle",
    x = "Life form",
    y = "Abundance"
  ) +
  ggplot2::geom_point() +
  ggplot2::theme_classic()

# GGplot with groups
fq_data_tae %>% 
  ggplot2::ggplot(
    ggplot2::aes(
      x=encounter_start_datetime, 
      y=canonical_name, 
      colour=life_form,
      shape=instance_id)) + 
  ggplot2::labs(
    title="Title", 
    subtitle="Subtitle", 
    x="Observation date", 
    y="Species", 
    colour="Life form",
    shape="Data collection device") +
  ggplot2::geom_point() + 
  ggplot2::theme_classic() + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

# Export
The rectangled data can now be exported. e.g. to CSV. Note that all list columns 
must be either unnested or dropped before exporting to CSV.

```{r export, eval=F}
fq_data %>% readr::write_csv("flora_quadrats.csv")
fq_data_tae %>% readr::write_csv("flora_quadrats_taxon_encounters.csv")
```
